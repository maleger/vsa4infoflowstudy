This git repository contains the stimuli used (.png files in original-images) and the data collected in the paper "Effects of Precise and Imprecise Value-Set Analysis (VSA) Information on Manual Code Analysis," published in the Binary Analysis Research (BAR) Workshop associated with the Network and Distributed System Security Symposium (NDSS) Conference, 2021.

None of these images or pseudo-code snippets is executable; they are hand-crafted problems used as stimuli in our tests.  We provide both the text files of the pseudo-code snippets and memory models (in the stimuli-text directory, each set in a sensitivity-inspired directory -- i.e., flow, path, field, and callsite) and the images we took of those files (in original-images).  The images provided were those actually used in  our tests, but we provide the text files for ease of reuse, modification, and correction.  We provide the instructions actually given to the participants in E-Prime-Instructions.pdf (separated on screens / by page as shown), and we provide the text for ease of modification in stimuli-text.

We also provide our anonymized raw data (ExperimentalData.xlsx), and we define our regions of interest (ROIs) for each problem -- including our definitions for the types of regions and discussions of where we loosened the region definitions due to the constraints of eye tracking data (roi-explanations.pdf).

If you use these stimuli or data in your research, please cite: Matzen, L. E., Leger, M. A., Reedy, G. (2021). Effects of Precise and Imprecise Value-Set Analysis (VSA) Information on Manual Code Analysis.  10.14722/bar.2021.23002.

======================================================================== 

How sensitive is a human analyst to the quality of the information they're getting? 

Do we have any evidence that improving the quality or character of the information given to the analyst makes a difference in their performance?
This is just basic "should we be trying to improve this kind of supporting information at all?" This test is not an end-point; it's to determine whether to proceed.

More / better information != better outcome. It might appear silly to ask this question, but we think we could come up with examples where additional information doesn't help.

These examples have assignments and memory references that may be confusing due to related conditionals or shared base pointers. These examples are written in a simple if-language that may benefit from flow or path sensitivity. The examples are inspired by various types of sensitivities in normal program analysis, each of which may lead to more or less precise points-to models depending on code characteristics. Our imprecise models reflect an analysis of the if-language that is flow- and path-insensitive; our precise models reflect an analysis that is flow- and path-sensitive.

Our problems ignore propagation of sensitivity. We only explore whether SENSITIVE is printed directly, not about whether an observable behavior indicates whether a SENSITIVE value was read or not. For example, none of our problems explore a case such as when a PUBLIC value is printed only when a SENSITIVE value is read. 

In all of the examples, MODEL A is the imprecise model, generated by a custom interpreter, and MODEL B is the most precise global model at the print statement, generated by hand.

FLOW INSPIRED PROBLEMS:
We explore problems inspired by flow sensitivity through straightline code. These examples are thus quite simple and rarely need an explanation beyond the two models (flow insensitive and flow sensitive).

PATH INSPIRED PROBLEMS:
These examples are inspired by cases that require path sensitivity to model precisely.

FIELD INSPIRED PROBLEMS:
We are inspired by field sensitivity, but we limit ourselves to path-based reasoning. We use a base pointer to unite all accesses to field in an object (i.e., we access all "fields" in an "object" by making a base (object) pointer point directly to each field), and we use a conditional to model accessing a particular field in an object.

CALLSITE INSPIRED PROBLEMS:
We are inspired by callsite sensitivity, but we must fit all on one page, and we limit ourselves to path-based reasoning. We model these problems by using conditionals to represent the callsite parameter assignment (generally call by value) and return site return value assignment. The function code is then inlined between A) the conditional statements representing the call and B) the conditional statements representing the return. The pre- and post- conditionals are generally identical, representing the benefit that might be had by reasoning with callsite sensitivity (i.e., identifying which parameters go with which return values). Any setup code from both call sites is placed before the pre-conditional, and any post-processing code from both call sites is placed after the post-conditional. Where the variables within the shared function are identical, the variables in the setup code and post-processing code are distinct for each function call site. Again, these are all merely inspired by callsite sensitivity.

This same technique might be used to model object sensitivity (or flavors thereof, e.g., type sensitivity): selecting to differentiate local variables and subsequent calls based on an allocation id to represent the object sensitivity and forcing an aliases between these differentiated local variables to model a lack of object sensitivity. This is based on the similar definitions of Record and Merge given by Smaragdakis: callsite sensitivity on page 36 and object sensitivity on page 38. 
